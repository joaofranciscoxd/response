{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "import schedule\n",
    "import sqlite3\n",
    "import time\n",
    "\n",
    "# Define the hours at which each code will be executed\n",
    "execution_time_code1 = '10:30'\n",
    "delta_minutes_code2 = 10\n",
    "\n",
    "# Define the GMT 0 time zone\n",
    "timezone = pytz.timezone('GMT')\n",
    "\n",
    "# Function to execute code 1\n",
    "def execute_code1():\n",
    "    print(\"Executing code 1...\")\n",
    "    # Call the function or code you want to execute for code 1\n",
    "\n",
    "# Function to execute code 2\n",
    "def execute_code2():\n",
    "    print(\"Executing code 2...\")\n",
    "    # Call the function or code you want to execute for code 2\n",
    "\n",
    "# Connect to the SQLite database\n",
    "connection = sqlite3.connect('sqlite:///wiki_data.db')\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Check if the \"next_execution\" table exists\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='next_execution';\")\n",
    "table_exists = cursor.fetchone()\n",
    "\n",
    "if table_exists:\n",
    "    # Check if there is a date and time record in the table\n",
    "    cursor.execute(\"SELECT * FROM next_execution LIMIT 1;\")\n",
    "    record = cursor.fetchone()\n",
    "    \n",
    "    if record is not None:\n",
    "        # Get the date and time from the record\n",
    "        start_date = datetime.datetime.strptime(record[0], '%Y-%m-%d %H:%M:%S%z')\n",
    "    else:\n",
    "        # Set the start date to July 8, 2023, at 10:30 in GMT 0 time zone\n",
    "        start_date = datetime.datetime(2023, 7, 8, hour=10, minute=30, tzinfo=timezone)\n",
    "else:\n",
    "    # Set the start date to July 8, 2023, at 10:30 in GMT 0 time zone\n",
    "    start_date = datetime.datetime(2023, 7, 8, hour=10, minute=30, tzinfo=timezone)\n",
    "\n",
    "# Calculate the start date for code 2\n",
    "start_date_code2 = start_date + datetime.timedelta(minutes=delta_minutes_code2)\n",
    "\n",
    "# Function to update the next execution date\n",
    "def update_next_execution():\n",
    "    # Calculate the next execution date\n",
    "    next_execution_date = datetime.datetime.now(timezone).date() + datetime.timedelta(days=1)\n",
    "    next_execution_datetime = datetime.datetime.combine(next_execution_date, start_date.time())\n",
    "    \n",
    "    if table_exists:\n",
    "        # Update the next execution date in the table\n",
    "        cursor.execute(\"UPDATE next_execution SET data = ?\", (next_execution_datetime,))\n",
    "    else:\n",
    "        # Create the \"next_execution\" table and insert the next execution date\n",
    "        cursor.execute(\"CREATE TABLE next_execution (data DATETIME);\")\n",
    "        cursor.execute(\"INSERT INTO next_execution (data) VALUES (?)\", (next_execution_datetime,))\n",
    "    \n",
    "    # Save the changes to the database\n",
    "    connection.commit()\n",
    "\n",
    "# Schedule the execution of the codes\n",
    "schedule.every().day.at(start_date.strftime('%H:%M')).do(execute_code1)\n",
    "schedule.every().day.at(start_date_code2.strftime('%H:%M')).do(execute_code2)\n",
    "schedule.every().day.at(execution_time_code2).do(update_next_execution)\n",
    "\n",
    "# Main loop\n",
    "while True:\n",
    "    # Check if the current date is equal to or later than the start date\n",
    "    if datetime.datetime.now(timezone) >= start_date:\n",
    "        # Execute the scheduled tasks\n",
    "        schedule.run_pending()\n",
    "    \n",
    "    # Wait 1 second before checking again\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# registrar o horario que foi coletado\n",
    "# checar se o conteúdo específico já existe, se sim, não gravar o fato em questão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sqlalchemy import create_engine, Column, Integer, String\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.orm import relationship\n",
    "from sqlalchemy import ForeignKey\n",
    "import os\n",
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_wikipedia():\n",
    "    # Configure the logger\n",
    "    logging.basicConfig(filename='app.log', level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s')\n",
    "\n",
    "    # Log the start of the web scraping process\n",
    "    logging.info('Starting web scraping...')\n",
    "\n",
    "    # Send GET request to Wikipedia's main page\n",
    "    response = requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "    \n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Extract the \"Did you know...\" section\n",
    "    did_you_know_section = soup.find(\"div\", {\"id\": \"mp-dyk\"})\n",
    "    \n",
    "    # Extract individual facts, preview links, and featured image\n",
    "    facts = []\n",
    "    for index, fact_item in enumerate(did_you_know_section.find_all(\"li\")):\n",
    "        fact_content = fact_item.text.strip()\n",
    "        \n",
    "        # Extract preview links\n",
    "        preview_links = []\n",
    "        for link in fact_item.find_all(\"a\"):\n",
    "            preview_content = link.get(\"title\")\n",
    "            preview_url = \"https://en.wikipedia.org\" + link.get(\"href\")\n",
    "            preview_links.append({\"content\": preview_content, \"url\": preview_url})\n",
    "        \n",
    "        # Extract featured image (if available)\n",
    "        featured_image = None\n",
    "        if index == 0: # Only for the first fact\n",
    "            element = did_you_know_section.find_all(\"a\")\n",
    "            if len(element) != 0:\n",
    "                image_element = element[0]\n",
    "                if image_element and \"image\" in image_element.get(\"class\", []):\n",
    "                    image_url = \"https://en.wikipedia.org\" + image_element.get(\"href\")\n",
    "                    image_caption = image_element.get(\"title\")\n",
    "                    featured_image = {\"url\": image_url, \"caption\": image_caption}\n",
    "\n",
    "        facts.append({\"content\": fact_content, \"preview_links\": preview_links, \"featured_image\": featured_image})\n",
    "    \n",
    "    # Log the number of facts found\n",
    "    logging.info(f\"Number of facts found: {len(facts)}\")\n",
    "    \n",
    "    # Exclude items starting from the one with 'Archive' in the content\n",
    "    facts_data = []\n",
    "    found_archive = False\n",
    "    for fact in facts:\n",
    "        if found_archive:\n",
    "            break\n",
    "        if 'Archive' in fact['content']:\n",
    "            found_archive = True\n",
    "        else:\n",
    "            facts_data.append(fact)\n",
    "    \n",
    "\n",
    "    # Database struct\n",
    "    Base = declarative_base()\n",
    "    class Fact(Base):\n",
    "        __tablename__ = \"facts\"\n",
    "        \n",
    "        id = Column(Integer, primary_key=True)\n",
    "        content = Column(String)\n",
    "        \n",
    "        preview_links = relationship(\"PreviewLink\", back_populates=\"fact\")\n",
    "        featured_image = relationship(\"FeaturedImage\", uselist=False, back_populates=\"fact\")\n",
    "\n",
    "    class PreviewLink(Base):\n",
    "        __tablename__ = \"preview_links\"\n",
    "        \n",
    "        id = Column(Integer, primary_key=True)\n",
    "        url = Column(String)\n",
    "        \n",
    "        fact_id = Column(Integer, ForeignKey(\"facts.id\"))\n",
    "        fact = relationship(\"Fact\", back_populates=\"preview_links\")\n",
    "\n",
    "    class FeaturedImage(Base):\n",
    "        __tablename__ = \"featured_images\"\n",
    "        \n",
    "        id = Column(Integer, primary_key=True)\n",
    "        image_url = Column(String)\n",
    "        caption = Column(String)\n",
    "        \n",
    "        fact_id = Column(Integer, ForeignKey(\"facts.id\"))\n",
    "        fact = relationship(\"Fact\", back_populates=\"featured_image\")\n",
    "    \n",
    "    # Create the database engine and session\n",
    "    database_file = \"wiki_data.db\"\n",
    "    database_exists = os.path.isfile(database_file)\n",
    "    engine = create_engine(f\"sqlite:///{database_file}\")\n",
    "    if not database_exists:\n",
    "        # Create the tables if the database doesn't exist\n",
    "        Base.metadata.create_all(engine)\n",
    "        logging.info('Database created.')\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "\n",
    "    # Store the data in the database\n",
    "    for fact_data in facts_data:\n",
    "        fact = Fact(content=fact_data[\"content\"])\n",
    "        \n",
    "        # Link preview links to the fact\n",
    "        for preview_link_data in fact_data[\"preview_links\"]:\n",
    "            preview_link = PreviewLink(url=preview_link_data[\"url\"])\n",
    "            fact.preview_links.append(preview_link)\n",
    "        \n",
    "        # Check if there's a featured image for the fact\n",
    "        featured_image_data = fact_data[\"featured_image\"]\n",
    "        if featured_image_data:\n",
    "            featured_image = FeaturedImage(image_url=featured_image_data[\"url\"], caption=featured_image_data[\"caption\"])\n",
    "            fact.featured_image = featured_image\n",
    "        \n",
    "        # Save the fact to the database\n",
    "        session.add(fact)\n",
    "    # Commit the changes to the database\n",
    "    session.commit()\n",
    "\n",
    "    # Log the completion of the web scraping process\n",
    "    logging.info('Web scraping completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_wikipedia()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_file = \"wiki_data.db\"\n",
    "database_exists = os.path.isfile(database_file)\n",
    "engine = create_engine(f\"sqlite:///{database_file}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import inspect\n",
    "\n",
    "# Create the inspector\n",
    "inspector = inspect(engine)\n",
    "\n",
    "# Get the table names\n",
    "table_names = inspector.get_table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_dfs = []\n",
    "# Iterate over the table names\n",
    "for table_name in table_names:\n",
    "    # Load the table content into a DataFrame\n",
    "    df = pd.read_sql_table(table_name, engine)\n",
    "    \n",
    "    # Print the table name\n",
    "    print(f\"Table: {table_name}\")\n",
    "    \n",
    "    print(df)\n",
    "    lista_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
